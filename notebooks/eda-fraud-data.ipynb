{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Exploratory Data Analysis - E-commerce Fraud Data\n",
        "\n",
        "This notebook performs comprehensive EDA on the Fraud_Data.csv dataset to understand:\n",
        "- Data structure and quality\n",
        "- Feature distributions\n",
        "- Class imbalance\n",
        "- Relationships between features and fraud\n",
        "\n",
        "**Author**: Adey Innovations Inc. Data Science Team  \n",
        "**Date**: December 2025\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Data Loading\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set display options\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', 100)\n",
        "pd.set_option('display.float_format', '{:.2f}'.format)\n",
        "\n",
        "# Set plot style\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "sns.set_palette('husl')\n",
        "\n",
        "# Add parent directory to path for imports\n",
        "import sys\n",
        "sys.path.append('..')\n",
        "from src.data_loader import load_fraud_data, load_ip_to_country, get_class_distribution\n",
        "from src.visualization import (\n",
        "    plot_class_distribution, \n",
        "    plot_numerical_distributions,\n",
        "    plot_categorical_distributions,\n",
        "    plot_correlation_matrix\n",
        ")\n",
        "\n",
        "print(\"Libraries imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the fraud dataset\n",
        "fraud_df = load_fraud_data('../data/raw/Fraud_Data.csv')\n",
        "print(f\"Dataset loaded successfully!\")\n",
        "print(f\"Shape: {fraud_df.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Initial Data Inspection\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display first few rows\n",
        "print(\"First 5 rows of the dataset:\")\n",
        "fraud_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data types and info\n",
        "print(\"\\nDataset Info:\")\n",
        "print(\"=\"*50)\n",
        "fraud_df.info()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Statistical summary\n",
        "print(\"\\nStatistical Summary:\")\n",
        "fraud_df.describe()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check for missing values\n",
        "print(\"\\nMissing Values:\")\n",
        "print(\"=\"*50)\n",
        "missing = fraud_df.isnull().sum()\n",
        "missing_pct = (missing / len(fraud_df)) * 100\n",
        "missing_df = pd.DataFrame({'Missing Count': missing, 'Missing %': missing_pct})\n",
        "print(missing_df[missing_df['Missing Count'] > 0])\n",
        "if missing_df['Missing Count'].sum() == 0:\n",
        "    print(\"No missing values found!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check for duplicates\n",
        "duplicates = fraud_df.duplicated().sum()\n",
        "print(f\"\\nDuplicate rows: {duplicates} ({duplicates/len(fraud_df)*100:.2f}%)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze class distribution\n",
        "class_dist = get_class_distribution(fraud_df)\n",
        "\n",
        "print(\"Class Distribution:\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Legitimate transactions (0): {class_dist['counts'][0]:,} ({class_dist['percentages'][0]:.2f}%)\")\n",
        "print(f\"Fraudulent transactions (1): {class_dist['counts'][1]:,} ({class_dist['percentages'][1]:.2f}%)\")\n",
        "print(f\"\\nImbalance Ratio: {class_dist['imbalance_ratio']:.1f}:1\")\n",
        "print(f\"\\nThis means for every 1 fraud case, there are ~{class_dist['imbalance_ratio']:.0f} legitimate cases.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize class distribution\n",
        "fig = plot_class_distribution(fraud_df['class'], title='E-commerce Fraud - Class Distribution')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Univariate Analysis\n",
        "\n",
        "### 4.1 Numerical Features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Numerical feature distributions\n",
        "numerical_cols = ['purchase_value', 'age']\n",
        "\n",
        "fig = plot_numerical_distributions(fraud_df, numerical_cols)\n",
        "plt.suptitle('Numerical Feature Distributions by Class', fontsize=14, y=1.02)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Purchase value analysis\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Overall distribution\n",
        "axes[0].hist(fraud_df['purchase_value'], bins=50, edgecolor='black', alpha=0.7)\n",
        "axes[0].set_xlabel('Purchase Value ($)')\n",
        "axes[0].set_ylabel('Frequency')\n",
        "axes[0].set_title('Distribution of Purchase Values')\n",
        "axes[0].axvline(fraud_df['purchase_value'].mean(), color='red', linestyle='--', \n",
        "                label=f'Mean: ${fraud_df[\"purchase_value\"].mean():.2f}')\n",
        "axes[0].axvline(fraud_df['purchase_value'].median(), color='green', linestyle='--', \n",
        "                label=f'Median: ${fraud_df[\"purchase_value\"].median():.2f}')\n",
        "axes[0].legend()\n",
        "\n",
        "# Box plot by class\n",
        "fraud_df.boxplot(column='purchase_value', by='class', ax=axes[1])\n",
        "axes[1].set_xlabel('Class (0=Legitimate, 1=Fraud)')\n",
        "axes[1].set_ylabel('Purchase Value ($)')\n",
        "axes[1].set_title('Purchase Value by Class')\n",
        "plt.suptitle('')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Statistics by class\n",
        "print(\"\\nPurchase Value Statistics by Class:\")\n",
        "print(fraud_df.groupby('class')['purchase_value'].describe())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.2 Categorical Features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Categorical feature analysis\n",
        "categorical_cols = ['source', 'browser', 'sex']\n",
        "\n",
        "fig = plot_categorical_distributions(fraud_df, categorical_cols)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Print fraud rates by categorical features\n",
        "print(\"Fraud Rate by Categorical Features:\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "for col in ['source', 'browser', 'sex']:\n",
        "    print(f\"\\n{col.upper()}:\")\n",
        "    fraud_stats = fraud_df.groupby(col).agg({\n",
        "        'class': ['count', 'sum', 'mean']\n",
        "    }).round(4)\n",
        "    fraud_stats.columns = ['Total', 'Fraud Count', 'Fraud Rate']\n",
        "    print(fraud_stats.sort_values('Fraud Rate', ascending=False))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Time-based Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create time features\n",
        "fraud_df['signup_hour'] = fraud_df['signup_time'].dt.hour\n",
        "fraud_df['signup_day'] = fraud_df['signup_time'].dt.dayofweek\n",
        "fraud_df['purchase_hour'] = fraud_df['purchase_time'].dt.hour\n",
        "fraud_df['purchase_day'] = fraud_df['purchase_time'].dt.dayofweek\n",
        "fraud_df['time_since_signup'] = (fraud_df['purchase_time'] - fraud_df['signup_time']).dt.total_seconds()\n",
        "fraud_df['time_since_signup_hours'] = fraud_df['time_since_signup'] / 3600\n",
        "\n",
        "print(\"Time features created successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fraud rate by hour of day\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "\n",
        "# Purchase hour\n",
        "fraud_by_hour = fraud_df.groupby('purchase_hour')['class'].mean()\n",
        "axes[0, 0].bar(fraud_by_hour.index, fraud_by_hour.values, color='steelblue')\n",
        "axes[0, 0].axhline(fraud_df['class'].mean(), color='red', linestyle='--', label='Overall Rate')\n",
        "axes[0, 0].set_xlabel('Hour of Day')\n",
        "axes[0, 0].set_ylabel('Fraud Rate')\n",
        "axes[0, 0].set_title('Fraud Rate by Purchase Hour')\n",
        "axes[0, 0].legend()\n",
        "\n",
        "# Transaction count by hour\n",
        "tx_by_hour = fraud_df.groupby('purchase_hour').size()\n",
        "axes[0, 1].bar(tx_by_hour.index, tx_by_hour.values, color='forestgreen')\n",
        "axes[0, 1].set_xlabel('Hour of Day')\n",
        "axes[0, 1].set_ylabel('Transaction Count')\n",
        "axes[0, 1].set_title('Transaction Volume by Hour')\n",
        "\n",
        "# Day of week\n",
        "day_names = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n",
        "fraud_by_day = fraud_df.groupby('purchase_day')['class'].mean()\n",
        "axes[1, 0].bar(range(7), fraud_by_day.values, color='coral')\n",
        "axes[1, 0].set_xticks(range(7))\n",
        "axes[1, 0].set_xticklabels(day_names)\n",
        "axes[1, 0].axhline(fraud_df['class'].mean(), color='red', linestyle='--', label='Overall Rate')\n",
        "axes[1, 0].set_xlabel('Day of Week')\n",
        "axes[1, 0].set_ylabel('Fraud Rate')\n",
        "axes[1, 0].set_title('Fraud Rate by Day of Week')\n",
        "axes[1, 0].legend()\n",
        "\n",
        "# Time since signup distribution\n",
        "for label, color in [(0, '#2ecc71'), (1, '#e74c3c')]:\n",
        "    subset = fraud_df[fraud_df['class'] == label]['time_since_signup_hours']\n",
        "    subset_clipped = subset[subset < 720]  # First 30 days\n",
        "    axes[1, 1].hist(subset_clipped, bins=50, alpha=0.6, label=f'Class {label}', color=color, density=True)\n",
        "\n",
        "axes[1, 1].set_xlabel('Hours Since Signup')\n",
        "axes[1, 1].set_ylabel('Density')\n",
        "axes[1, 1].set_title('Time Since Signup Distribution (First 30 days)')\n",
        "axes[1, 1].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze time since signup more closely - CRITICAL INSIGHT\n",
        "print(\"Time Since Signup Analysis:\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "def categorize_time(hours):\n",
        "    if hours < 1:\n",
        "        return '< 1 hour'\n",
        "    elif hours < 24:\n",
        "        return '1-24 hours'\n",
        "    elif hours < 168:\n",
        "        return '1-7 days'\n",
        "    elif hours < 720:\n",
        "        return '1-4 weeks'\n",
        "    else:\n",
        "        return '> 1 month'\n",
        "\n",
        "fraud_df['signup_time_bucket'] = fraud_df['time_since_signup_hours'].apply(categorize_time)\n",
        "\n",
        "time_analysis = fraud_df.groupby('signup_time_bucket').agg({\n",
        "    'class': ['count', 'sum', 'mean']\n",
        "}).round(4)\n",
        "time_analysis.columns = ['Total', 'Fraud Count', 'Fraud Rate']\n",
        "\n",
        "# Reorder\n",
        "order = ['< 1 hour', '1-24 hours', '1-7 days', '1-4 weeks', '> 1 month']\n",
        "time_analysis = time_analysis.reindex([o for o in order if o in time_analysis.index])\n",
        "print(time_analysis)\n",
        "\n",
        "# Visualize\n",
        "fig, ax = plt.subplots(figsize=(10, 5))\n",
        "colors = plt.cm.Reds(np.linspace(0.3, 0.9, len(time_analysis)))\n",
        "bars = ax.bar(time_analysis.index, time_analysis['Fraud Rate'], color=colors)\n",
        "ax.axhline(fraud_df['class'].mean(), color='blue', linestyle='--', label='Overall Rate')\n",
        "ax.set_xlabel('Time Since Signup')\n",
        "ax.set_ylabel('Fraud Rate')\n",
        "ax.set_title('Fraud Rate by Time Since Signup')\n",
        "ax.legend()\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n⚠️ KEY INSIGHT: Transactions shortly after signup have MUCH higher fraud rates!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Correlation Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Select numerical columns for correlation\n",
        "numerical_features = ['purchase_value', 'age', 'purchase_hour', 'purchase_day', \n",
        "                      'time_since_signup_hours', 'class']\n",
        "\n",
        "correlation_df = fraud_df[numerical_features].copy()\n",
        "corr_matrix = correlation_df.corr()\n",
        "\n",
        "# Plot\n",
        "fig, ax = plt.subplots(figsize=(10, 8))\n",
        "mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
        "sns.heatmap(corr_matrix, mask=mask, annot=True, fmt='.3f', cmap='RdBu_r',\n",
        "            center=0, square=True, linewidths=0.5, ax=ax)\n",
        "ax.set_title('Feature Correlation Matrix', fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Show correlations with target\n",
        "print(\"\\nCorrelation with Target (class):\")\n",
        "print(\"=\"*50)\n",
        "target_corr = corr_matrix['class'].drop('class').sort_values(key=abs, ascending=False)\n",
        "print(target_corr)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Key Findings Summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*70)\n",
        "print(\"EDA KEY FINDINGS - E-COMMERCE FRAUD DATA\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(f\"\"\"\n",
        "1. CLASS IMBALANCE:\n",
        "   - Fraud rate: {fraud_df['class'].mean()*100:.2f}%\n",
        "   - Imbalance ratio: {class_dist['imbalance_ratio']:.1f}:1\n",
        "   - This is a SEVERE imbalance requiring special handling (SMOTE, class weights)\n",
        "\n",
        "2. TIME-BASED PATTERNS:\n",
        "   - Transactions within first hour after signup show HIGHEST fraud risk\n",
        "   - This is a critical feature for fraud detection\n",
        "   - Fraud rates vary by hour of day and day of week\n",
        "\n",
        "3. DEVICE PATTERNS:\n",
        "   - Devices shared by multiple users may indicate fraud rings\n",
        "   - Device-level features should be engineered\n",
        "\n",
        "4. CATEGORICAL INSIGHTS:\n",
        "   - Different sources (SEO, Ads, Direct) show varying fraud rates\n",
        "   - Browser choice may correlate with fraud likelihood\n",
        "\n",
        "5. DATA QUALITY:\n",
        "   - No missing values\n",
        "   - Minimal/no duplicates\n",
        "   - Clean dataset ready for feature engineering\n",
        "\n",
        "RECOMMENDED FEATURES TO ENGINEER:\n",
        "   - time_since_signup (CRITICAL)\n",
        "   - hour_of_day, day_of_week\n",
        "   - user_transaction_count\n",
        "   - device_unique_users\n",
        "   - device_transaction_count\n",
        "\"\"\")\n",
        "\n",
        "print(\"=\"*70)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
