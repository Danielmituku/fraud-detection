{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Feature Engineering for Fraud Detection\n",
        "\n",
        "This notebook focuses on:\n",
        "- Geolocation integration (IP to Country mapping)\n",
        "- Time-based feature engineering\n",
        "- Transaction velocity features\n",
        "- Device features\n",
        "- Data transformation (scaling, encoding)\n",
        "- Class imbalance handling (SMOTE)\n",
        "\n",
        "**Author**: Adey Innovations Inc. Data Science Team  \n",
        "**Date**: December 2025\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Data Loading\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Add parent directory to path\n",
        "import sys\n",
        "sys.path.append('..')\n",
        "from src.data_loader import (\n",
        "    load_fraud_data, load_ip_to_country, load_creditcard_data,\n",
        "    map_ip_to_country, clean_fraud_data, clean_creditcard_data,\n",
        "    get_class_distribution\n",
        ")\n",
        "from src.feature_engineering import (\n",
        "    create_time_features, create_transaction_velocity_features,\n",
        "    create_device_features, encode_categorical_features,\n",
        "    scale_numerical_features, prepare_features_for_modeling\n",
        ")\n",
        "\n",
        "print(\"Libraries imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load datasets\n",
        "fraud_df = load_fraud_data('../data/raw/Fraud_Data.csv')\n",
        "ip_country_df = load_ip_to_country('../data/raw/IpAddress_to_Country.csv')\n",
        "cc_df = load_creditcard_data('../data/raw/creditcard.csv')\n",
        "\n",
        "print(\"Datasets loaded:\")\n",
        "print(f\"  - Fraud_Data: {fraud_df.shape}\")\n",
        "print(f\"  - IP to Country: {ip_country_df.shape}\")\n",
        "print(f\"  - Credit Card: {cc_df.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Geolocation Integration (IP to Country)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Examine IP address data\n",
        "print(\"IP Address Sample (Fraud Data):\")\n",
        "print(fraud_df['ip_address'].head())\n",
        "print(f\"\\nIP range: {fraud_df['ip_address'].min()} - {fraud_df['ip_address'].max()}\")\n",
        "\n",
        "print(\"\\nIP to Country Sample:\")\n",
        "print(ip_country_df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Map IP addresses to countries\n",
        "print(\"Mapping IP addresses to countries...\")\n",
        "fraud_df_geo = map_ip_to_country(fraud_df, ip_country_df)\n",
        "\n",
        "print(f\"\\nMapping complete!\")\n",
        "print(f\"Countries found: {fraud_df_geo['country'].nunique()}\")\n",
        "print(f\"\\nTop 10 countries by transaction count:\")\n",
        "print(fraud_df_geo['country'].value_counts().head(10))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze fraud by country\n",
        "fraud_by_country = fraud_df_geo.groupby('country').agg({\n",
        "    'class': ['count', 'sum', 'mean']\n",
        "}).round(4)\n",
        "fraud_by_country.columns = ['Total', 'Fraud_Count', 'Fraud_Rate']\n",
        "fraud_by_country = fraud_by_country.sort_values('Fraud_Rate', ascending=False)\n",
        "\n",
        "# Filter to countries with at least 100 transactions\n",
        "significant_countries = fraud_by_country[fraud_by_country['Total'] >= 100]\n",
        "\n",
        "print(\"Fraud Rates by Country (min 100 transactions):\")\n",
        "print(significant_countries.head(15))\n",
        "\n",
        "# Visualize\n",
        "fig, ax = plt.subplots(figsize=(12, 6))\n",
        "top_fraud_countries = significant_countries.head(15)\n",
        "colors = plt.cm.Reds(np.linspace(0.3, 0.9, len(top_fraud_countries)))\n",
        "ax.barh(range(len(top_fraud_countries)), top_fraud_countries['Fraud_Rate'].values, color=colors)\n",
        "ax.set_yticks(range(len(top_fraud_countries)))\n",
        "ax.set_yticklabels(top_fraud_countries.index)\n",
        "ax.invert_yaxis()\n",
        "ax.axvline(fraud_df_geo['class'].mean(), color='blue', linestyle='--', label='Overall Rate')\n",
        "ax.set_xlabel('Fraud Rate')\n",
        "ax.set_title('Top 15 Countries by Fraud Rate')\n",
        "ax.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Time-Based Feature Engineering\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create time-based features\n",
        "fraud_df_fe = create_time_features(fraud_df_geo)\n",
        "\n",
        "print(\"Time features created:\")\n",
        "print(fraud_df_fe[['hour_of_day', 'day_of_week', 'is_weekend', 'time_since_signup']].head())\n",
        "print(f\"\\nNew columns: hour_of_day, day_of_week, is_weekend, time_since_signup\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Transaction Velocity and Device Features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create velocity features\n",
        "fraud_df_fe = create_transaction_velocity_features(fraud_df_fe)\n",
        "print(\"Velocity features created:\")\n",
        "print(fraud_df_fe[['user_total_transactions', 'user_transaction_number']].describe())\n",
        "\n",
        "# Create device features\n",
        "fraud_df_fe = create_device_features(fraud_df_fe)\n",
        "print(\"\\nDevice features created:\")\n",
        "print(fraud_df_fe[['device_total_transactions', 'device_unique_users']].describe())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Encoding and Scaling\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Encode categorical features\n",
        "categorical_cols = ['source', 'browser', 'sex', 'country']\n",
        "fraud_df_encoded, encoding_info = encode_categorical_features(fraud_df_fe, categorical_cols)\n",
        "\n",
        "print(f\"Original shape: {fraud_df_fe.shape}\")\n",
        "print(f\"After encoding: {fraud_df_encoded.shape}\")\n",
        "print(f\"\\nEncoded columns sample:\")\n",
        "encoded_cols = [c for c in fraud_df_encoded.columns if any(cat in c for cat in categorical_cols)]\n",
        "print(encoded_cols[:10])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare features for modeling\n",
        "X_fraud, y_fraud = prepare_features_for_modeling(\n",
        "    fraud_df_encoded, \n",
        "    target_col='class',\n",
        "    drop_cols=['user_id', 'signup_time', 'purchase_time', 'device_id', 'ip_address']\n",
        ")\n",
        "\n",
        "print(f\"Features shape: {X_fraud.shape}\")\n",
        "print(f\"Target shape: {y_fraud.shape}\")\n",
        "print(f\"\\nFeature columns:\")\n",
        "print(X_fraud.columns.tolist())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Handling Class Imbalance (SMOTE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Document class distribution before SMOTE\n",
        "print(\"Class Distribution BEFORE SMOTE:\")\n",
        "print(\"=\"*50)\n",
        "print(y_fraud.value_counts())\n",
        "print(f\"\\nFraud Rate: {y_fraud.mean()*100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Apply SMOTE (demonstration - in practice, apply only to training data)\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split first\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_fraud, y_fraud, test_size=0.2, random_state=42, stratify=y_fraud\n",
        ")\n",
        "\n",
        "print(f\"Training set: {X_train.shape}\")\n",
        "print(f\"Test set: {X_test.shape}\")\n",
        "print(f\"\\nTraining class distribution:\")\n",
        "print(y_train.value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Apply SMOTE to training data only\n",
        "smote = SMOTE(random_state=42, sampling_strategy=0.5)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "print(\"Class Distribution AFTER SMOTE:\")\n",
        "print(\"=\"*50)\n",
        "print(pd.Series(y_train_resampled).value_counts())\n",
        "print(f\"\\nFraud Rate: {y_train_resampled.mean()*100:.2f}%\")\n",
        "\n",
        "# Visualize\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "# Before SMOTE\n",
        "axes[0].bar(['Legitimate', 'Fraud'], [len(y_train[y_train==0]), len(y_train[y_train==1])], \n",
        "            color=['#2ecc71', '#e74c3c'])\n",
        "axes[0].set_title('Before SMOTE')\n",
        "axes[0].set_ylabel('Count')\n",
        "\n",
        "# After SMOTE\n",
        "axes[1].bar(['Legitimate', 'Fraud'], \n",
        "            [len(y_train_resampled[y_train_resampled==0]), len(y_train_resampled[y_train_resampled==1])],\n",
        "            color=['#2ecc71', '#e74c3c'])\n",
        "axes[1].set_title('After SMOTE')\n",
        "axes[1].set_ylabel('Count')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Credit Card Data Preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare credit card data\n",
        "# The V1-V28 features are already PCA transformed\n",
        "# Only Amount and Time need scaling\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "cc_df_processed = cc_df.copy()\n",
        "\n",
        "# Scale Amount and Time\n",
        "scaler = StandardScaler()\n",
        "cc_df_processed['Amount_scaled'] = scaler.fit_transform(cc_df_processed[['Amount']])\n",
        "cc_df_processed['Time_scaled'] = scaler.fit_transform(cc_df_processed[['Time']])\n",
        "\n",
        "# Prepare features\n",
        "X_cc = cc_df_processed.drop(columns=['Class', 'Amount', 'Time'])\n",
        "y_cc = cc_df_processed['Class']\n",
        "\n",
        "print(f\"Credit Card Features: {X_cc.shape}\")\n",
        "print(f\"Columns: {X_cc.columns.tolist()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Save Processed Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save processed datasets\n",
        "# Uncomment to save\n",
        "# fraud_df_encoded.to_csv('../data/processed/fraud_data_processed.csv', index=False)\n",
        "# cc_df_processed.to_csv('../data/processed/creditcard_processed.csv', index=False)\n",
        "\n",
        "print(\"Feature Engineering Complete!\")\n",
        "print(\"=\"*50)\n",
        "print(f\"\"\"\n",
        "Summary:\n",
        "- E-commerce Fraud Data:\n",
        "  * IP to Country mapping: {fraud_df_geo['country'].nunique()} countries\n",
        "  * Time features: hour_of_day, day_of_week, time_since_signup\n",
        "  * Velocity features: user_total_transactions, device_unique_users\n",
        "  * Final features: {X_fraud.shape[1]}\n",
        "  \n",
        "- Credit Card Data:\n",
        "  * Amount and Time scaled\n",
        "  * V1-V28 PCA features preserved\n",
        "  * Final features: {X_cc.shape[1]}\n",
        "  \n",
        "- SMOTE applied to training data to handle class imbalance\n",
        "\"\"\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
